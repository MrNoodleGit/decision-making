{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('C:\\\\Users\\\\ronal\\\\Documents\\\\GitHub\\\\decision-making\\\\graph_builder') # Append path where graph_builder.py is saved\n",
    "from graph_builder import *\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Build all graphs from the available tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir('treebuilderUpdated')\n",
    "graphs = {}\n",
    "for file in file_names:\n",
    "    graphs[file.replace('.csv', '')] = build_graph('treebuilderUpdated\\\\' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # We begin to write the path analysis program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path()\n",
    "def parse_path_string(path_string):\n",
    "    a = path_string.replace('p','')\n",
    "    b = a.split(';')\n",
    "    b.remove('')\n",
    "#     e = [tuple(int(s) for s in i.split(',')) for i in d]         Useful for converting strings of tuples in real tuples\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path(). Returns the root node for a graph.\n",
    "def root_node(graph):\n",
    "    root = [v for v, d in graph.in_degree() if d == 0][0]\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_nodes(graph):\n",
    "    leaves = [v for v, d in graph.out_degree() if d == 0]\n",
    "    return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path()\n",
    "def node_value_calculation(graph, node, steps_so_far, prior_prob):\n",
    "    new_observations = graph.nodes[node]['new_observations']\n",
    "    ep = graph.nodes[node]['node_ep']\n",
    "    node_value = ((steps_so_far * new_observations) + ep) * prior_prob\n",
    "    \n",
    "    return node_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path(). Returns the node in successors which corresponds to the input_location if it is found. Returns False otherwise.\n",
    "def location_in_successors(graph, input_location, current_node):\n",
    "    node_location_dict = (nx.get_node_attributes(graph, 'node_location'))\n",
    "    successor_list = list(graph.successors(current_node))\n",
    "    \n",
    "    for successor in successor_list:\n",
    "        if node_location_dict[successor] == input_location:\n",
    "            return successor\n",
    "        \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_successors(graph, node):\n",
    "    num_of_successors = len(list(graph.successors(node)))\n",
    "    \n",
    "    return num_of_successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_successors(graph, node, index=None): # Returns list of successors. If given an index, returns the successor with that index in the list.\n",
    "    if index is None:\n",
    "        return list(graph.successors(node))\n",
    "    \n",
    "    else:\n",
    "        return list(graph.successors(node))[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_node_paths(graph, source='root'):\n",
    "    all_paths = []\n",
    "    \n",
    "    if source == 'root':\n",
    "        for path in nx.all_simple_paths(graph, root_node(graph), leaf_nodes(graph)):\n",
    "            all_paths.append(path)\n",
    "    else:\n",
    "        for path in nx.all_simple_paths(graph, source, leaf_nodes(graph)):\n",
    "            all_paths.append(path)\n",
    "            \n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_subject_paths(graph, subject_sequence): # Input list of nodes subject visited. Returns possible paths that subject could have taken to reach leaf nodes.\n",
    "                                            # Use if last node in subject_sequence is not in leaf_nodes().\n",
    "    subject_set = set(subject_sequence)\n",
    "    num_common_nodes = [] # Number of nodes that each sequence in all_node_paths() has in common with subject_sequence\n",
    "    for path in all_node_paths(graph):\n",
    "        num_common_nodes.append(len(set(path) & subject_set))\n",
    "\n",
    "#     print(num_common_nodes)\n",
    "\n",
    "    similarity_degree = max(num_common_nodes)\n",
    "\n",
    "    possible_subject_paths = [path for idx, path in enumerate(all_node_paths(graph)) if num_common_nodes[idx] == similarity_degree]\n",
    "    \n",
    "    return possible_subject_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_path_value(graph, path): # Returns node_value of the node sequence (as defined by the last node in the path).\n",
    "    last_node = path[-1]\n",
    "    \n",
    "    path_value = graph.nodes[last_node]['path_value']\n",
    "    \n",
    "    return path_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_node_lists(graph, subject_sequence): # Input list of nodes subject visited. Returns list of sequences of remaining nodes for each possible subject path.\n",
    "    _possible_subject_paths = possible_subject_paths(graph, subject_sequence)\n",
    "    num_possible_paths = len(_possible_subject_paths)\n",
    "    extra_node_lists = [[node for node in _possible_subject_paths[i] if node not in subject_sequence] for i in range(num_possible_paths)]\n",
    "    \n",
    "    return extra_node_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_prob(graph):\n",
    "    _root_node = root_node(graph)\n",
    "    total_black_squares = graph.nodes[_root_node]['black_remains']\n",
    "    prior_prob = 1/total_black_squares\n",
    "    \n",
    "    return prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_location(graph, step, visited_locations, current_node):\n",
    "    \n",
    "    successors = get_successors(graph, current_node)\n",
    "    node_location_dict = nx.get_node_attributes(graph, 'node_location')\n",
    "    \n",
    "    successor_locations = [node_location_dict[k] for k in node_location_dict if k in successors] # Successor locations for current node    \n",
    "    node_locations = list(node_location_dict.values())\n",
    "    \n",
    "    valid_locations = deepcopy(visited_locations)\n",
    "\n",
    "    valid_locations.update(successor_locations)\n",
    "    \n",
    "    if step in node_locations:\n",
    "        if step in valid_locations:\n",
    "            pass\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_node_paths(graph, chosen_path): # Returns dict of all node sequences (except for the full path that the subject chose) that reach leaf nodes and their respective values\n",
    "    _all_node_paths = all_node_paths(graph)\n",
    "    alt_node_paths = _all_node_paths.copy()\n",
    "    alt_node_paths.remove(chosen_path)\n",
    "    \n",
    "    path_value_dict = {','.join(path): get_last_path_value(graph, path) for path in alt_node_paths} # Keys are a string of nodes seperated by commas. Use list.split() method to convert into list.\n",
    "    \n",
    "    return path_value_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set leaf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_leaf_values(subject_graph, node_sequence): # Input the subject's empirical node sequence. Returns a nested list of leaf values for each node the subject visited, chosen path_value, and the chosen_path\n",
    "    value_decision_list = []\n",
    "    last_visited_node = node_sequence[-1]\n",
    "    \n",
    "    chosen_path_value, chosen_path = min((get_last_path_value(subject_graph, path), path) for path in all_node_paths(subject_graph) if last_visited_node in path)\n",
    "        \n",
    "    for node in node_sequence:\n",
    "        try:\n",
    "            value_choices = sorted(\n",
    "                                    [\n",
    "                                    (min(get_last_path_value(subject_graph, path) for path in all_node_paths(subject_graph, successor)), successor) for successor in get_successors(subject_graph, node)\n",
    "                                    ], key=lambda pair: pair[1] in chosen_path, reverse=True\n",
    "                                    )\n",
    "\n",
    "            value_choices = [value for (value, node) in value_choices]\n",
    "            value_decision_list.append(value_choices)\n",
    "\n",
    "        except ValueError:\n",
    "            value_choices = sorted(\n",
    "                                    [\n",
    "                                    (subject_graph.nodes[successor]['path_value'], successor) for successor in get_successors(subject_graph, node)\n",
    "                                    ], key=lambda pair: pair[1] in chosen_path, reverse=True\n",
    "                                    )\n",
    "\n",
    "            value_choices = [value for (value, node) in value_choices]\n",
    "            value_decision_list.append(value_choices)\n",
    "\n",
    "        subject_graph.nodes[node]['leaf_values'] = value_choices\n",
    "\n",
    "    value_decision_list.pop()\n",
    "\n",
    "    return value_decision_list, chosen_path_value, chosen_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Tau calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_vs_tau_prob_array(nested_value_lists, taus_array):\n",
    "    value_vs_tau_prob_array = []\n",
    "    list_of_value_arrays = [np.array(list) for list in nested_value_lists]\n",
    "    taus_prior_prob = 1 / taus_array\n",
    "    \n",
    "    for value_array in list_of_value_arrays:\n",
    "        value_row = np.array([])\n",
    "        \n",
    "        for tau in taus_array:\n",
    "            value_row = np.append(value_row, softmax((-value_array) / tau)[0]) # We only need the conditional probability for the first node_value (i.e node_value of node the subject chose)\n",
    "        \n",
    "        value_vs_tau_prob_array.append(value_row)\n",
    "    value_vs_tau_prob_array = np.array(value_vs_tau_prob_array)\n",
    "    # We insert TAUS_PRIOR_PROB into first row of array to account for prior\n",
    "    value_vs_tau_prob_array = np.insert(value_vs_tau_prob_array, 0, taus_prior_prob, axis=0)\n",
    "\n",
    "    return value_vs_tau_prob_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_tau_prob(value_vs_tau_prob_array):\n",
    "    posterior_tau_prob = np.prod(value_vs_tau_prob_array, axis=0)\n",
    "    \n",
    "    return posterior_tau_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_posterior_tau_prob(posterior_tau_prob):\n",
    "    sum = np.sum(posterior_tau_prob)\n",
    "    norm_posterior_tau_prob = posterior_tau_prob / sum\n",
    "    \n",
    "    return norm_posterior_tau_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_tau(nested_value_lists):\n",
    "    TAUS = np.geomspace(0.05, 50)\n",
    "    \n",
    "    _value_vs_tau_prob_array = value_vs_tau_prob_array(nested_value_lists, TAUS)\n",
    "    _posterior_tau_prob = posterior_tau_prob(_value_vs_tau_prob_array)\n",
    "    _norm_posterior_tau_prob = norm_posterior_tau_prob(_posterior_tau_prob)\n",
    "    \n",
    "    expected_tau = np.sum(TAUS * _norm_posterior_tau_prob)\n",
    "    \n",
    "    return expected_tau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set edge weight to next-node value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_edge_attribute(graph, node, successor, node_value, attribute='weight'):\n",
    "    graph.succ[node][successor][attribute] = node_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate path value give a sequence of nodes by adding node values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_node_and_path_value(graph, node_sequence): # Sets value of a path by adding all node values in the input sequence. Assigns the corresponding node_value and path_value to each node\n",
    "    PRIOR_PROB = prior_prob(graph)\n",
    "    steps_from_root = 0\n",
    "    path_value = 0\n",
    "    \n",
    "    for node in node_sequence[1:]:\n",
    "        steps_from_root += graph.nodes[node]['steps_from_parent']\n",
    "        node_value = node_value_calculation(graph, node, steps_from_root, PRIOR_PROB)\n",
    "        path_value += node_value\n",
    "        \n",
    "        graph.nodes[node]['node_value'] = node_value\n",
    "        graph.nodes[node]['path_value'] = path_value\n",
    "        graph.nodes[node]['steps_from_root'] = steps_from_root\n",
    "        \n",
    "    return path_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Path analysis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_path(graph, path): # Takes path string as input.\n",
    "    PRIOR_PROB = prior_prob(graph)\n",
    "    steps_so_far = 0\n",
    "    \n",
    "    current_node_value = 0\n",
    "    current_node = root_node(graph)\n",
    "    node_sequence = [root_node(graph)]\n",
    "    path_value = 0\n",
    "    input_path = parse_path_string(path)\n",
    "    LEAF_NODES = leaf_nodes(graph)\n",
    "    subject_graph = deepcopy(graph)\n",
    "    steps_from_parent = 0\n",
    "    \n",
    "    all_visited_locations = {'(0,0)'} # First visited location is subject's starting position.\n",
    "    subject_graph.nodes[root_node(subject_graph)]['node_value'] = 0\n",
    "    \n",
    "    for step in input_path[1:]:\n",
    "        if valid_location(subject_graph, step, all_visited_locations, current_node) is False:\n",
    "            return ['ERROR_PATH', step, current_node]\n",
    "        else:\n",
    "            if location_in_successors(subject_graph, step, current_node) is not False:\n",
    "                steps_so_far += 1\n",
    "                steps_from_parent += 1\n",
    "                next_node = location_in_successors(subject_graph, step, current_node)\n",
    "                subject_graph.nodes[next_node]['steps_from_root'] = steps_so_far\n",
    "                subject_graph.nodes[next_node]['steps_from_parent'] = steps_from_parent\n",
    "                \n",
    "                next_node_value = node_value_calculation(subject_graph, next_node, steps_so_far, PRIOR_PROB)\n",
    "                subject_graph.nodes[next_node]['node_value'] = next_node_value\n",
    "                path_value += next_node_value\n",
    "                \n",
    "                node_sequence.append(next_node)\n",
    "                next_path_value = path_value\n",
    "                subject_graph.nodes[next_node]['path_value'] = next_path_value\n",
    "\n",
    "                current_node = next_node\n",
    "                steps_from_parent = 0\n",
    "                \n",
    "            else:\n",
    "                steps_so_far += 1\n",
    "                steps_from_parent += 1\n",
    "            \n",
    "            all_visited_locations.add(step)\n",
    "            \n",
    "    empirical_path_value = path_value # Saves path node_value at the last node the subject visited in experiment\n",
    "    empirical_path = node_sequence.copy() # Saves sequence of nodes subject visited in experiment\n",
    "    empirical_path_string = ','.join(empirical_path)\n",
    "    empirical_last_node = current_node\n",
    "    empirical_steps_so_far = steps_so_far\n",
    "        \n",
    "#     print('empirical path is', empirical_path)\n",
    "#     print('empirical step number is', steps_so_far)\n",
    "#     print('empirical pathvalue is', empirical_path_value)\n",
    "#     print('empirical last node is', empirical_last_node)\n",
    "    \n",
    "#   ------------------------------------------------------------------------------------------------------\n",
    "    _extra_node_lists = extra_node_lists(subject_graph, empirical_path)\n",
    "    path_comparison_dict = {}\n",
    "    \n",
    "    for node_list in _extra_node_lists:\n",
    "        node_sequence = empirical_path.copy()\n",
    "        path_value = empirical_path_value\n",
    "        current_node = empirical_last_node\n",
    "        steps_so_far = empirical_steps_so_far\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                next_node = node_list.pop(0)\n",
    "                steps_so_far += subject_graph.succ[current_node][next_node]['weight']\n",
    "                subject_graph.nodes[next_node]['steps_from_root'] = steps_so_far\n",
    "\n",
    "                next_node_value = node_value_calculation(subject_graph, next_node, steps_so_far, PRIOR_PROB)\n",
    "                subject_graph.nodes[next_node]['node_value'] = next_node_value\n",
    "                path_value += next_node_value\n",
    "                \n",
    "                node_sequence.append(next_node)\n",
    "                next_path_value = path_value\n",
    "                subject_graph.nodes[next_node]['path_value'] = next_path_value\n",
    "                \n",
    "                current_node = next_node\n",
    "                \n",
    "            except IndexError: # Stop while loop when we have reached the last node in the current node list\n",
    "                path_comparison_dict[','.join(node_sequence)] = path_value\n",
    "                break\n",
    "                \n",
    "    _all_node_paths = all_node_paths(subject_graph)\n",
    "    \n",
    "    for path in _all_node_paths:\n",
    "        set_node_and_path_value(subject_graph, path)\n",
    "    \n",
    "    nested_value_lists, chosen_path_value, chosen_path = set_leaf_values(subject_graph, empirical_path)\n",
    "    expected_tau = get_expected_tau(nested_value_lists)\n",
    "    \n",
    "    output = [empirical_path_string, round(chosen_path_value, 3), round(expected_tau, 3)]\n",
    "    \n",
    "    return output\n",
    "    \n",
    "#     print(node_sequence)\n",
    "#     print(path_comparison_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Analyze experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data_file):\n",
    "    experiment_data_frame = pd.read_csv(data_file, sep='\\t')\n",
    "\n",
    "    previous_subject = ''\n",
    "    previous_world = ''\n",
    "    previous_path = ''\n",
    "    # previous_index = 0\n",
    "    parsed_data = []\n",
    "\n",
    "    # i = 0\n",
    "    for row in experiment_data_frame.itertuples():\n",
    "        if previous_subject != row[1]:\n",
    "            parsed_data.append([previous_subject, previous_world, previous_path])\n",
    "\n",
    "    #     previous_index = index + 2\n",
    "        previous_subject = row[1]\n",
    "        previous_world = row[2]\n",
    "        previous_path = row[3]\n",
    "\n",
    "    parsed_data.append( # Add last row of the data frame manually, since algorithm above misses it\n",
    "                      [experiment_data_frame.iloc[-1]['subject'], \n",
    "                       experiment_data_frame.iloc[-1]['world'], \n",
    "                       experiment_data_frame.iloc[-1]['squarepath']\n",
    "                      ]\n",
    "                     )    \n",
    "\n",
    "    #     if i == 2000:\n",
    "    #         break\n",
    "    #     i += 1\n",
    "\n",
    "    parsed_data.pop(0)\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = parse_data('SquareLabelsWithRT_E2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(parsed_data):\n",
    "    input_data = deepcopy(parsed_data)\n",
    "    output_data = []\n",
    "    error_data = []\n",
    "\n",
    "    for row in input_data: # Analyze path that each subject followed\n",
    "        graph_name = row[1]\n",
    "        input_path = row[2]\n",
    "        path_analysis = analyze_path(graphs[graph_name], input_path)\n",
    "        row.extend(path_analysis)\n",
    "\n",
    "        if path_analysis[0] == 'ERROR_PATH':\n",
    "            error_data.append(row)\n",
    "            \n",
    "        else:\n",
    "            output_data.append(row)\n",
    "\n",
    "    print(f'{len(input_data)} paths analyzed')\n",
    "    print(f'There are {len(error_data)} error paths')\n",
    "    \n",
    "    return output_data, error_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512 paths analyzed\n",
      "There are 161 error paths\n"
     ]
    }
   ],
   "source": [
    "output_data, error_data = analyze_data(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data analysis as csv\n",
    "def export_results(output_data):\n",
    "    column_titles = ['subject', 'world', 'square_path', 'subject_node_path', 'chosen_path_value', 'expected_tau'] # The first item in the column 'all_values' is the chosen node_value\n",
    "\n",
    "    with open('anaylzed_subject_data.csv', 'w') as file:\n",
    "        file_writer = csv.writer(file, delimiter='\\t')\n",
    "        file_writer.writerow(column_titles)\n",
    "\n",
    "        for row in output_data:\n",
    "            file_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export error data\n",
    "def export_error_data(error_data):\n",
    "    column_titles = ['subject', 'world', 'square_path', 'path_type', 'error_step', 'error_node']\n",
    "\n",
    "    with open('error_data.csv', 'w') as file:\n",
    "        file_writer = csv.writer(file, delimiter='\\t')\n",
    "        file_writer.writerow(column_titles)\n",
    "\n",
    "        for row in error_data:\n",
    "            file_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_error_data(error_data)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
