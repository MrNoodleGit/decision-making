{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('C:\\\\Users\\\\ronal\\\\Documents\\\\GitHub\\\\decision-making\\\\graph_builder') # Append path where graph_builder.py is saved\n",
    "from graph_builder import *\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Build all graphs from the available tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir('treebuilderUpdated')\n",
    "graphs = {}\n",
    "for file in file_names:\n",
    "    graphs[file.replace('.csv', '')] = build_graph('treebuilderUpdated\\\\' + file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # We begin to write the path analysis program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path()\n",
    "def parse_path_string(path_string):\n",
    "    a = path_string.replace('p','')\n",
    "    b = a.split(';')\n",
    "    b.remove('')\n",
    "#     e = [tuple(int(s) for s in i.split(',')) for i in d]         Useful for converting strings of tuples in real tuples\n",
    "    \n",
    "    return b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path(). Returns the root node for a graph.\n",
    "def root_node(graph):\n",
    "    root = [v for v, d in graph.in_degree() if d == 0][0]\n",
    "    return root\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_nodes(graph):\n",
    "    leaves = [v for v, d in graph.out_degree() if d == 0]\n",
    "    return leaves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path()\n",
    "def node_value_calculation(graph, node, steps_so_far, prior_prob):\n",
    "    new_observations = graph.nodes[node]['new_observations']\n",
    "    ep = graph.nodes[node]['node_ep']\n",
    "    node_value = ((steps_so_far * new_observations) + ep) * prior_prob\n",
    "    \n",
    "    return node_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path(). Returns the node in successors which corresponds to the input_location if it is found. Returns False otherwise.\n",
    "def location_in_successors(graph, input_location, current_node):\n",
    "    node_location_dict = (nx.get_node_attributes(graph, 'node_location'))\n",
    "    successor_list = list(graph.successors(current_node))\n",
    "    \n",
    "    for successor in successor_list:\n",
    "        if node_location_dict[successor] == input_location:\n",
    "            return successor\n",
    "        \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_successors(graph, node):\n",
    "    num_of_successors = len(list(graph.successors(node)))\n",
    "    \n",
    "    return num_of_successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_successors(graph, node, index=None): # Returns list of successors. If given an index, returns the successor with that index in the list.\n",
    "    if index is None:\n",
    "        return list(graph.successors(node))\n",
    "    \n",
    "    else:\n",
    "        return list(graph.successors(node))[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_node_paths(graph):\n",
    "    all_paths = []\n",
    "    \n",
    "    for path in nx.all_simple_paths(graph, root_node(graph), leaf_nodes(graph)):\n",
    "        all_paths.append(path)\n",
    "        \n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_subject_paths(graph, subject_sequence): # Input list of nodes subject visited. Returns possible paths that subject could have taken to reach leaf nodes.\n",
    "                                            # Use if last node in subject_sequence is not in leaf_nodes().\n",
    "    subject_set = set(subject_sequence)\n",
    "    num_common_nodes = [] # Number of nodes that each sequence in all_node_paths() has in common with subject_sequence\n",
    "    for path in all_node_paths(graph):\n",
    "        num_common_nodes.append(len(set(path) & subject_set))\n",
    "\n",
    "#     print(num_common_nodes)\n",
    "\n",
    "    similarity_degree = max(num_common_nodes)\n",
    "\n",
    "    possible_subject_paths = [path for idx, path in enumerate(all_node_paths(graph)) if num_common_nodes[idx] == similarity_degree]\n",
    "    \n",
    "    return possible_subject_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_path_value(graph, path): # Returns node_value of the node sequence (as defined by the last node in the path).\n",
    "    last_node = path[-1]\n",
    "    \n",
    "    path_value = graph.nodes[last_node]['path_value']\n",
    "    \n",
    "    return path_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_node_lists(graph, subject_sequence): # Input list of nodes subject visited. Returns list of sequences of remaining nodes for each possible subject path.\n",
    "    _possible_subject_paths = possible_subject_paths(graph, subject_sequence)\n",
    "    num_possible_paths = len(_possible_subject_paths)\n",
    "    extra_node_lists = [[node for node in _possible_subject_paths[i] if node not in subject_sequence] for i in range(num_possible_paths)]\n",
    "    \n",
    "    return extra_node_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_prob(graph):\n",
    "    _root_node = root_node(graph)\n",
    "    total_black_squares = graph.nodes[_root_node]['black_remains']\n",
    "    prior_prob = 1/total_black_squares\n",
    "    \n",
    "    return prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_location(graph, step, visited_locations, current_node):\n",
    "    \n",
    "    successors = get_successors(graph, current_node)\n",
    "    node_location_dict = nx.get_node_attributes(graph, 'node_location')\n",
    "    \n",
    "    successor_locations = [node_location_dict[k] for k in node_location_dict if k in successors] # Successor locations for current node    \n",
    "    node_locations = list(node_location_dict.values())\n",
    "    \n",
    "    valid_locations = deepcopy(visited_locations)\n",
    "\n",
    "    valid_locations.update(successor_locations)\n",
    "    \n",
    "    if step in node_locations:\n",
    "        if step in valid_locations:\n",
    "            pass\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_node_paths(graph, chosen_path): # Returns dict of all node sequences (except for the full path that the subject chose) that reach leaf nodes and their respective values\n",
    "    _all_node_paths = all_node_paths(graph)\n",
    "    alt_node_paths = _all_node_paths.copy()\n",
    "    alt_node_paths.remove(chosen_path)\n",
    "    \n",
    "    path_value_dict = {','.join(path): calculate_path_value(graph, path) for path in alt_node_paths} # Keys are a string of nodes seperated by commas. Use list.split() method to convert into list.\n",
    "    \n",
    "    return path_value_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Update graph nodes with successor values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_values(graph, node_list): # Input graph and list of nodes. Returns list of path values for each node.\n",
    "    path_values = []\n",
    "    for node in node_list:\n",
    "        path_values.append(graph.nodes[node]['path_value'])\n",
    "        \n",
    "    return path_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_leaf_values(subject_graph, final_path): # Sets attribute 'successor_values' to each node in the subjet's final path; returns nested lists of values for each node\n",
    "    final_path_values = get_path_values(subject_graph, final_path)\n",
    "    value_decision_list = []\n",
    "    for node in final_path:\n",
    "        successors = get_successors(subject_graph, node)\n",
    "        successor_values = get_path_values(subject_graph, successors)\n",
    "        sorted_successor_values = sorted(successor_values, key=lambda node_value: node_value in final_path_values, reverse=True) # The first node_value will be the node_value of the node the subject chose\n",
    "        \n",
    "        subject_graph.nodes[node]['successor_values'] = sorted_successor_values\n",
    "        \n",
    "        value_decision_list.append(sorted_successor_values)\n",
    "    value_decision_list.remove([])\n",
    "        \n",
    "    return value_decision_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Tau calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_vs_tau_prob_array(nested_value_lists, taus_array):\n",
    "    value_vs_tau_prob_array = []\n",
    "    list_of_value_arrays = [np.array(list) for list in nested_value_lists]\n",
    "    taus_prior_prob = 1 / taus_array\n",
    "    \n",
    "    for value_array in list_of_value_arrays:\n",
    "        value_row = np.array([])\n",
    "        \n",
    "        for tau in taus_array:\n",
    "            value_row = np.append(value_row, softmax((-value_array) / tau)[0]) # We only need the conditional probability for the first node_value (i.e node_value of node the subject chose)\n",
    "        \n",
    "        value_vs_tau_prob_array.append(value_row)\n",
    "    value_vs_tau_prob_array = np.array(value_vs_tau_prob_array)\n",
    "    # We insert TAUS_PRIOR_PROB into first row of array to account for prior\n",
    "    value_vs_tau_prob_array = np.insert(value_vs_tau_prob_array, 0, taus_prior_prob, axis=0)\n",
    "\n",
    "    return value_vs_tau_prob_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_tau_prob(value_vs_tau_prob_array):\n",
    "    posterior_tau_prob = np.prod(value_vs_tau_prob_array, axis=0)\n",
    "    \n",
    "    return posterior_tau_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_posterior_tau_prob(posterior_tau_prob):\n",
    "    sum = np.sum(posterior_tau_prob)\n",
    "    norm_posterior_tau_prob = posterior_tau_prob / sum\n",
    "    \n",
    "    return norm_posterior_tau_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_tau(nested_value_lists):\n",
    "    TAUS = np.geomspace(0.05, 50)\n",
    "    \n",
    "    _value_vs_tau_prob_array = value_vs_tau_prob_array(nested_value_lists, TAUS)\n",
    "    _posterior_tau_prob = posterior_tau_prob(_value_vs_tau_prob_array)\n",
    "    _norm_posterior_tau_prob = norm_posterior_tau_prob(_posterior_tau_prob)\n",
    "    \n",
    "    expected_tau = np.sum(TAUS * _norm_posterior_tau_prob)\n",
    "    \n",
    "    return expected_tau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set edge weight to next-node value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_edge_attribute(graph, node, successor, node_value, attribute='weight'):\n",
    "    graph.succ[node][successor][attribute] = node_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Path analysis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_path(graph, path): # Takes path string as input.\n",
    "    PRIOR_PROB = prior_prob(graph)\n",
    "    steps_so_far = 0\n",
    "    \n",
    "    current_node_value = 0\n",
    "    current_node = root_node(graph)\n",
    "    node_sequence = [root_node(graph)]\n",
    "    path_value = 0\n",
    "    input_path = parse_path_string(path)\n",
    "    LEAF_NODES = leaf_nodes(graph)\n",
    "    subject_graph = deepcopy(graph)\n",
    "    \n",
    "    all_visited_locations = {'(0,0)'} # First visited location is subject's starting position.\n",
    "    subject_graph.nodes[root_node(subject_graph)]['node_value'] = 0\n",
    "    \n",
    "    for step in input_path[1:]:\n",
    "        if valid_location(subject_graph, step, all_visited_locations, current_node) is False:\n",
    "            return ['ERROR_PATH', step, current_node]\n",
    "        else:\n",
    "            if location_in_successors(subject_graph, step, current_node) is not False:\n",
    "                steps_so_far += 1\n",
    "                next_node = location_in_successors(subject_graph, step, current_node)\n",
    "                subject_graph.nodes[next_node]['steps_from_root'] = steps_so_far\n",
    "                \n",
    "                next_node_value = node_value_calculation(subject_graph, next_node, steps_so_far, PRIOR_PROB)\n",
    "                subject_graph.nodes[next_node]['node_value'] = next_node_value\n",
    "\n",
    "                edge_value = node_value_calculation(subject_graph, next_node, steps_so_far, PRIOR_PROB)\n",
    "                set_edge_attribute(subject_graph, current_node, next_node, edge_value)\n",
    "                path_value += edge_value\n",
    "                \n",
    "                node_sequence.append(next_node)\n",
    "                next_path_value = path_value\n",
    "                subject_graph.nodes[next_node]['path_value'] = next_path_value\n",
    "\n",
    "                current_node = next_node\n",
    "                print(next_node)\n",
    "                \n",
    "            else:\n",
    "                steps_so_far += 1\n",
    "            all_visited_locations.add(step)\n",
    "    empirical_path_value = path_value # Saves path node_value at the last node the subject visited in experiment\n",
    "    empirical_path = node_sequence.copy() # Saves sequence of nodes subject visited in experiment\n",
    "    empirical_last_node = current_node\n",
    "    empirical_steps_so_far = steps_so_far\n",
    "        \n",
    "#     print('empirical path is', empirical_path)\n",
    "#     print('empirical step number is', steps_so_far)\n",
    "#     print('empirical pathvalue is', empirical_path_value)\n",
    "#     print('empirical last node is', empirical_last_node)\n",
    "    \n",
    "#   ------------------------------------------------------------------------------------------------------\n",
    "    _extra_node_lists = extra_node_lists(subject_graph, empirical_path)\n",
    "    path_comparison_dict = {}\n",
    "    \n",
    "    for node_list in _extra_node_lists:\n",
    "        node_sequence = empirical_path.copy()\n",
    "        path_value = empirical_path_value\n",
    "        current_node = empirical_last_node\n",
    "        steps_so_far = empirical_steps_so_far\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                next_node = node_list.pop(0)\n",
    "                print(f'current_node is {current_node}')\n",
    "                print(f'next node is {next_node}')\n",
    "                steps_so_far += subject_graph.succ[current_node][next_node]['steps_from_parent']\n",
    "                subject_graph.nodes[next_node]['steps_from_root'] = steps_so_far\n",
    "\n",
    "                next_node_value = node_value_calculation(subject_graph, next_node, steps_so_far, PRIOR_PROB)\n",
    "                subject_graph.nodes[next_node]['node_value'] = next_node_value\n",
    "\n",
    "                edge_value = node_value_calculation(subject_graph, next_node, steps_so_far, PRIOR_PROB)\n",
    "                set_edge_attribute(subject_graph, current_node, next_node, edge_value)\n",
    "                path_value += edge_value\n",
    "                \n",
    "                node_sequence.append(next_node)\n",
    "                next_path_value = path_value\n",
    "                subject_graph.nodes[next_node]['path_value'] = next_path_value\n",
    "                \n",
    "                current_node = next_node\n",
    "                \n",
    "            except IndexError: # Stop while loop when we have reached the last node in the current node list\n",
    "                path_comparison_dict[','.join(node_sequence)] = path_value\n",
    "                break\n",
    "                \n",
    "    final_path_string = min(path_comparison_dict, key = lambda k: path_comparison_dict[k]) # If the subject did not reach a leaf, this is the path we assume the subject would have taken (the optimal choice).\n",
    "    final_path = final_path_string.split(',')\n",
    "    final_path_value = path_comparison_dict[final_path_string]\n",
    "    print(final_path)\n",
    "    \n",
    "    nested_value_lists = set_leaf_values(subject_graph, final_path) # set_leaf_values returns nested lists of leaf-node node_value choices for each node in the final path sequence\n",
    "    expected_tau = get_expected_tau(nested_value_lists)\n",
    "    \n",
    "    alt_path_values = sorted(list(\n",
    "        alt_node_paths(subject_graph, final_path).values()\n",
    "                                ))\n",
    "    \n",
    "    all_values = [str(round(final_path_value, 3))]\n",
    "    all_values.extend([str(round(num, 3)) for num in alt_path_values])\n",
    "    \n",
    "    \n",
    "    output = [final_path_string, round(final_path_value, 3), round(expected_tau, 3)]\n",
    "    output.append(';'.join(all_values))\n",
    "    \n",
    "    return output, subject_graph\n",
    "    \n",
    "#     print(node_sequence)\n",
    "#     print(path_comparison_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N2554\n",
      "N6588\n",
      "current_node is N6588\n",
      "next node is N7822\n",
      "['N6609', 'N2554', 'N6588', 'N7822']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['N6609,N2554,N6588,N7822', 6.8, 0.22, '6.8;8.2;10.6']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, H = analyze_path(graphs['courtyard'], 'p(0,0);p(1,0);p(2,0);p(3,0);p(3,1);p(3,2);')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Analyze experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data_file):\n",
    "    experiment_data_frame = pd.read_csv(data_file, sep='\\t')\n",
    "\n",
    "    previous_subject = ''\n",
    "    previous_world = ''\n",
    "    previous_path = ''\n",
    "    # previous_index = 0\n",
    "    parsed_data = []\n",
    "\n",
    "    # i = 0\n",
    "    for row in experiment_data_frame.itertuples():\n",
    "        if previous_subject != row[1]:\n",
    "            parsed_data.append([previous_subject, previous_world, previous_path])\n",
    "\n",
    "    #     previous_index = index + 2\n",
    "        previous_subject = row[1]\n",
    "        previous_world = row[2]\n",
    "        previous_path = row[3]\n",
    "\n",
    "    parsed_data.append( # Add last row of the data frame manually, since algorithm above misses it\n",
    "                      [experiment_data_frame.iloc[-1]['subject'], \n",
    "                       experiment_data_frame.iloc[-1]['world'], \n",
    "                       experiment_data_frame.iloc[-1]['squarepath']\n",
    "                      ]\n",
    "                     )    \n",
    "\n",
    "    #     if i == 2000:\n",
    "    #         break\n",
    "    #     i += 1\n",
    "\n",
    "    parsed_data.pop(0)\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = parse_data('SquareLabelsWithRT_E2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(parsed_data):\n",
    "    input_data = deepcopy(parsed_data)\n",
    "    output_data = []\n",
    "    error_data = []\n",
    "\n",
    "    for row in input_data: # Analyze path that each subject followed\n",
    "        graph_name = row[1]\n",
    "        input_path = row[2]\n",
    "        path_analysis = analyze_path(graphs[graph_name], input_path)\n",
    "        row.extend(path_analysis)\n",
    "\n",
    "        if path_analysis[0] == 'ERROR_PATH':\n",
    "            error_data.append(row)\n",
    "            \n",
    "        else:\n",
    "            output_data.append(row)\n",
    "\n",
    "    print(f'{len(input_data)} paths analyzed')\n",
    "    print(f'There are {len(error_data)} error paths')\n",
    "    \n",
    "    return output_data, error_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data, error_data = analyze_data(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data analysis as csv\n",
    "def export_results(output_data):\n",
    "    column_titles = ['subject', 'world', 'square_path', 'chosen_node_path', 'chosen_value', 'expected_tau', 'all_values'] # The first item in the column 'all_values' is the chosen node_value\n",
    "\n",
    "    with open('anaylzed_subject_data.csv', 'w') as file:\n",
    "        file_writer = csv.writer(file, delimiter='\\t')\n",
    "        file_writer.writerow(column_titles)\n",
    "\n",
    "        for row in output_data:\n",
    "            file_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export error data\n",
    "def export_error_data(error_data):\n",
    "    column_titles = ['subject', 'world', 'square_path', 'path_type', 'error_step', 'error_node']\n",
    "\n",
    "    with open('error_data.csv', 'w') as file:\n",
    "        file_writer = csv.writer(file, delimiter='\\t')\n",
    "        file_writer.writerow(column_titles)\n",
    "\n",
    "        for row in error_data:\n",
    "            file_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_error_data(error_data)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
