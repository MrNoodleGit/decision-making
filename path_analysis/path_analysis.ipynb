{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build all graphs from the available tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('C:\\\\Users\\\\ronal\\\\Documents\\\\GitHub\\\\decision-making\\\\graph_builder') # Append path where graph_builder.py is saved\n",
    "from graph_builder import *\n",
    "\n",
    "file_names = os.listdir('treebuilderUpdated')\n",
    "graphs = {}\n",
    "for file in file_names:\n",
    "    graphs[file.replace('.csv', '')] = build_graph('treebuilderUpdated\\\\' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We begin to write the path analysis program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyzePath()\n",
    "def parsePathString(path_string):\n",
    "    a = path_string.replace('p','')\n",
    "    b = a.split(';')\n",
    "    b.remove('')\n",
    "#     e = [tuple(int(s) for s in i.split(',')) for i in d]         Useful for converting strings of tuples in real tuples\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyzePath(). Returns the root node for a graph.\n",
    "def rootNode(graph):\n",
    "    root = [v for v, d in graph.in_degree() if d == 0][0]\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leafNodes(graph):\n",
    "    leaves = [v for v, d in graph.out_degree() if d == 0]\n",
    "    return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyzePath()\n",
    "def valueCalc(graph, node, steps_so_far, prior_prob):\n",
    "    new_observations = graph.nodes[node]['new_observations']\n",
    "    ep = graph.nodes[node]['node_ep']\n",
    "    value = ((steps_so_far * new_observations) + ep) * prior_prob\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyzePath(). Returns the node in successors which corresponds to the input_location if it is found. Returns False otherwise.\n",
    "def isInSuccessors(graph, input_position, current_node):\n",
    "    node_pos_dict = (nx.get_node_attributes(graph, 'node_location'))\n",
    "    successor_list = list(graph.successors(current_node))\n",
    "    \n",
    "    for successor in successor_list:\n",
    "        if node_pos_dict[successor] == input_position:\n",
    "            return successor\n",
    "        \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numSuccessors(graph, node):\n",
    "    num_of_successors = len(list(graph.successors(node)))\n",
    "    \n",
    "    return num_of_successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSuccessors(graph, node, index=None): # Returns list of successors. If given an index, returns the successor with that index in the list.\n",
    "    if index is None:\n",
    "        return list(graph.successors(node))\n",
    "    \n",
    "    else:\n",
    "        return list(graph.successors(node))[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allNodePaths(graph):\n",
    "    all_paths = []\n",
    "    \n",
    "    for path in nx.all_simple_paths(graph, rootNode(graph), leafNodes(graph)):\n",
    "        all_paths.append(path)\n",
    "        \n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possibleSubjectPaths(graph, subject_sequence): # Input list of nodes subject visited. Returns possible paths that subject could have taken to reach leaf nodes.\n",
    "                                            # Use if last node in subject_sequence is not in leafNodes().\n",
    "    subject_set = set(subject_sequence)\n",
    "    num_common_nodes = [] # Number of nodes that each sequence in allNodePaths() has in common with subject_sequence\n",
    "    for path in allNodePaths(graph):\n",
    "        num_common_nodes.append(len(set(path) & subject_set))\n",
    "\n",
    "#     print(num_common_nodes)\n",
    "\n",
    "    similarity_degree = max(num_common_nodes)\n",
    "\n",
    "    possible_subject_paths = [path for idx, path in enumerate(allNodePaths(graph)) if num_common_nodes[idx] == similarity_degree]\n",
    "    \n",
    "    \n",
    "    return possible_subject_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genericPathValue(graph, path): # Returns (generic) value of the node path (as defined by the last node in the path).\n",
    "    last_node = path[-1]\n",
    "    \n",
    "    generic_path_value = graph.nodes[last_node]['node_value']\n",
    "    \n",
    "    return generic_path_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraNodeLists(graph, subject_sequence): # Input list of nodes subject visited. Returns list of sequences of remaining nodes for each possible subject path.\n",
    "    possible_subject_paths = possibleSubjectPaths(graph, subject_sequence)\n",
    "    num_possible_paths = len(possible_subject_paths)\n",
    "    extra_node_lists = [[node for node in possible_subject_paths[i] if node not in subject_sequence] for i in range(num_possible_paths)]\n",
    "    \n",
    "    return extra_node_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def priorProb(graph):\n",
    "    root_node = rootNode(graph)\n",
    "    total_black_squares = graph.nodes[root_node]['black_remains']\n",
    "    prior_prob = 1/total_black_squares\n",
    "    \n",
    "    return prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validLocation(graph, step, visited_locations, current_node, previous_node):\n",
    "    if previous_node == '':\n",
    "        return\n",
    "    \n",
    "    successors = getSuccessors(graph, current_node)\n",
    "    previous_successors = getSuccessors(graph, previous_node)\n",
    "    \n",
    "    node_location_dict = nx.get_node_attributes(graph, 'node_location')\n",
    "    \n",
    "    successor_locations = [node_location_dict[k] for k in node_location_dict if k in successors] # Successor locations for current node\n",
    "    previous_successor_locations = [node_location_dict[k] for k in node_location_dict if k in previous_successors] # Successor locations for previous node\n",
    "    \n",
    "    node_locations = list(node_location_dict.values())\n",
    "    \n",
    "    valid_locations = visited_locations.copy()\n",
    "\n",
    "    valid_locations.update(successor_locations)\n",
    "    valid_locations.update(previous_successor_locations)\n",
    "    \n",
    "    \n",
    "    if step in node_locations:\n",
    "        if step in valid_locations:\n",
    "            pass\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def altNodePaths(graph, chosen_path):\n",
    "    all_node_paths = allNodePaths(graph)\n",
    "    alt_node_paths = all_node_paths.copy()\n",
    "    alt_node_paths.remove(chosen_path)\n",
    "    \n",
    "    path_value_dict = {','.join(path):genericPathValue(graph, path) for path in alt_node_paths} # Keys are a string of nodes seperated by commas. Use list.split() method to convert into list.\n",
    "    \n",
    "    return path_value_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path analysis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzePath(graph, path): # Takes path string as input.\n",
    "    previous_node = ''\n",
    "    current_node = rootNode(graph)\n",
    "    steps_so_far = 0\n",
    "    node_sequence = [rootNode(graph)]\n",
    "    path_value = 0\n",
    "    input_path = parsePathString(path)\n",
    "    LEAF_NODES = leafNodes(graph)\n",
    "    PRIOR_PROB = priorProb(graph)\n",
    "    all_visited_locations = {'(0,0)'} # First visited location is subject's starting position.\n",
    "\n",
    "    for step in input_path[1:]:\n",
    "        if validLocation(graph, step, all_visited_locations, current_node, previous_node) is False:\n",
    "            return ['ERROR_PATH', step, current_node]\n",
    "        else:\n",
    "            if isInSuccessors(graph, step, current_node) is not False:\n",
    "                previous_node = current_node\n",
    "                current_node = isInSuccessors(graph, step, current_node)\n",
    "                node_sequence.append(current_node)\n",
    "                steps_so_far += 1\n",
    "                path_value += valueCalc(graph, current_node, steps_so_far, PRIOR_PROB)\n",
    "            else:\n",
    "                steps_so_far += 1\n",
    "            all_visited_locations.add(step)\n",
    "    \n",
    "    empirical_path_value = path_value # Saves path value at the last node the subject visited in experiment\n",
    "    empirical_path = node_sequence # Saves sequence of nodes subject visited in experiment\n",
    "    empirical_last_node = current_node\n",
    "    \n",
    "#     print('empirical path is', empirical_path)\n",
    "#     print('empirical step number is', steps_so_far)\n",
    "#     print('empirical pathvalue is', empirical_path_value)\n",
    "#     print('empirical last node is', empirical_last_node)\n",
    "    \n",
    "#     #####################################################################################\n",
    "\n",
    "    extra_node_lists = extraNodeLists(graph, empirical_path)\n",
    "    path_comparison_dict = {}\n",
    "    \n",
    "    for node_list in extraNodeLists(graph, empirical_path):\n",
    "        node_sequence = empirical_path\n",
    "        path_value = empirical_path_value\n",
    "        current_node = empirical_last_node\n",
    "        \n",
    "        while True:\n",
    "            try: \n",
    "                next_node = node_list.pop(0)\n",
    "                steps_so_far += graph.succ[current_node][next_node]['steps_from_parent']                \n",
    "                current_node = next_node\n",
    "                node_sequence.append(current_node)\n",
    "                path_value += valueCalc(graph, current_node, steps_so_far, PRIOR_PROB)\n",
    "            except IndexError:\n",
    "                path_comparison_dict[','.join(node_sequence)] = path_value\n",
    "                break\n",
    "                \n",
    "    final_path_string = min(path_comparison_dict, key = lambda k: path_comparison_dict[k]) # If the subject did not reach a leaf, this is the path we assume the subject would have taken (the optimal choice).\n",
    "    final_path = final_path_string.split(',')\n",
    "    final_path_value = path_comparison_dict[final_path_string]\n",
    "#     print('The chosen node path is', final_path, 'with value', final_path_value) # We only care about the value of the paths, so it does not matter if more than one path has the same value.\n",
    "    alt_path_values = sorted(list(altNodePaths(graph, final_path).values()))\n",
    "#     print('The alternative values are ', alt_path_values)\n",
    "    all_values = [str(round(final_path_value, 3))]\n",
    "    all_values.extend([str(round(num, 3)) for num in alt_path_values])\n",
    "\n",
    "    output = [final_path_string, round(final_path_value, 3)]\n",
    "    output.append(';'.join(all_values))\n",
    "    \n",
    "    return output\n",
    "    \n",
    "#   print(node_sequence)\n",
    "#   print(path_comparison_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experiment_data_frame = pd.read_csv('squareLabelsWithRT_E2.csv', sep='\\t')\n",
    "\n",
    "previous_subject = ''\n",
    "previous_world = ''\n",
    "previous_path = ''\n",
    "# previous_index = 0\n",
    "input_data = []\n",
    "\n",
    "# i = 0\n",
    "for row in experiment_data_frame.itertuples():\n",
    "    if previous_subject != row[1]:\n",
    "        input_data.append([previous_subject, previous_world, previous_path])\n",
    "    \n",
    "#     previous_index = index + 2\n",
    "    previous_subject = row[1]\n",
    "    previous_world = row[2]\n",
    "    previous_path = row[3]\n",
    "    \n",
    "input_data.append( # Add last row of the data frame manually, since algorithm above misses it\n",
    "                  [experiment_data_frame.iloc[-1]['subject'], \n",
    "                   experiment_data_frame.iloc[-1]['world'], \n",
    "                   experiment_data_frame.iloc[-1]['squarepath']\n",
    "                  ]\n",
    "                 )    \n",
    "    \n",
    "#     if i == 2000:\n",
    "#         break\n",
    "#     i += 1\n",
    "    \n",
    "input_data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512 paths analyzed\n",
      "There are 117 error paths\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "num_error_paths = 0\n",
    "output_data = deepcopy(input_data)\n",
    "\n",
    "for row in output_data: # Analyze path that each subject followed\n",
    "    graph_name = row[1]\n",
    "    input_path = row[2]\n",
    "    path_analysis = analyzePath(graphs[graph_name], input_path)\n",
    "    row.extend(path_analysis)\n",
    "    \n",
    "    if path_analysis[0] == 'ERROR_PATH':\n",
    "        num_error_paths += 1\n",
    "\n",
    "print(f'{len(output_data)} paths analyzed')\n",
    "print(f'There are {num_error_paths} error paths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export path analysis as csv\n",
    "import csv\n",
    "\n",
    "column_titles = ['subject', 'world', 'square_path', 'chosen_node_path', 'chosen_value', 'all_values'] # The first item in the column 'all_values' is the chosen value\n",
    "\n",
    "with open('anaylzed_subject_data.csv', 'w') as file:\n",
    "    file_writer = csv.writer(file, delimiter='\\t')\n",
    "    file_writer.writerow(column_titles)\n",
    "    \n",
    "    for row in output_data:\n",
    "        file_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data = []\n",
    "for row in output_data:\n",
    "    if row[3] == 'ERROR_PATH':\n",
    "        error_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export error data\n",
    "import csv\n",
    "\n",
    "column_titles = ['subject', 'world', 'square_path', 'path_type', 'error_step', 'error_node']\n",
    "\n",
    "with open('error_data.csv', 'w') as file:\n",
    "    file_writer = csv.writer(file, delimiter='\\t')\n",
    "    file_writer.writerow(column_titles)\n",
    "    \n",
    "    for row in error_data:\n",
    "        file_writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
