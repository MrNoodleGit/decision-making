{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from graph_builder import *\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Build all graphs from the available tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('C:\\\\Users\\\\ronal\\\\Documents\\\\GitHub\\\\decision-making\\\\graph_builder') # Append path where graph_builder.py is saved\n",
    "\n",
    "file_names = os.listdir('treebuilderUpdated')\n",
    "graphs = {}\n",
    "for file in file_names:\n",
    "    graphs[file.replace('.csv', '')] = build_graph('treebuilderUpdated\\\\' + file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # We begin to write the path analysis program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path()\n",
    "def parse_path_string(path_string):\n",
    "    a = path_string.replace('p','')\n",
    "    b = a.split(';')\n",
    "    b.remove('')\n",
    "#     e = [tuple(int(s) for s in i.split(',')) for i in d]         Useful for converting strings of tuples in real tuples\n",
    "    \n",
    "    return b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path(). Returns the root node for a graph.\n",
    "def root_node(graph):\n",
    "    root = [v for v, d in graph.in_degree() if d == 0][0]\n",
    "    return root\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_nodes(graph):\n",
    "    leaves = [v for v, d in graph.out_degree() if d == 0]\n",
    "    return leaves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path()\n",
    "def value_calculation(graph, node, steps_so_far, prior_prob):\n",
    "    new_observations = graph.nodes[node]['new_observations']\n",
    "    ep = graph.nodes[node]['node_ep']\n",
    "    value = ((steps_so_far * new_observations) + ep) * prior_prob\n",
    "    \n",
    "    return value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for analyze_path(). Returns the node in successors which corresponds to the input_location if it is found. Returns False otherwise.\n",
    "def location_in_successors(graph, input_location, current_node):\n",
    "    node_location_dict = (nx.get_node_attributes(graph, 'node_location'))\n",
    "    successor_list = list(graph.successors(current_node))\n",
    "    \n",
    "    for successor in successor_list:\n",
    "        if node_location_dict[successor] == input_location:\n",
    "            return successor\n",
    "        \n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_successors(graph, node):\n",
    "    num_of_successors = len(list(graph.successors(node)))\n",
    "    \n",
    "    return num_of_successors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_successors(graph, node, index=None): # Returns list of successors. If given an index, returns the successor with that index in the list.\n",
    "    if index is None:\n",
    "        return list(graph.successors(node))\n",
    "    \n",
    "    else:\n",
    "        return list(graph.successors(node))[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_node_paths(graph):\n",
    "    all_paths = []\n",
    "    \n",
    "    for path in nx.all_simple_paths(graph, root_node(graph), leaf_nodes(graph)):\n",
    "        all_paths.append(path)\n",
    "        \n",
    "    return all_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_subject_paths(graph, subject_sequence): # Input list of nodes subject visited. Returns possible paths that subject could have taken to reach leaf nodes.\n",
    "                                            # Use if last node in subject_sequence is not in leaf_nodes().\n",
    "    subject_set = set(subject_sequence)\n",
    "    num_common_nodes = [] # Number of nodes that each sequence in all_node_paths() has in common with subject_sequence\n",
    "    for path in all_node_paths(graph):\n",
    "        num_common_nodes.append(len(set(path) & subject_set))\n",
    "\n",
    "#     print(num_common_nodes)\n",
    "\n",
    "    similarity_degree = max(num_common_nodes)\n",
    "\n",
    "    possible_subject_paths = [path for idx, path in enumerate(all_node_paths(graph)) if num_common_nodes[idx] == similarity_degree]\n",
    "    \n",
    "    \n",
    "    return possible_subject_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_path_value(graph, path): # Returns (generic) value of the node path (as defined by the last node in the path).\n",
    "    last_node = path[-1]\n",
    "    \n",
    "    generic_path_value = graph.nodes[last_node]['node_value']\n",
    "    \n",
    "    return generic_path_value\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_node_lists(graph, subject_sequence): # Input list of nodes subject visited. Returns list of sequences of remaining nodes for each possible subject path.\n",
    "    _possible_subject_paths = possible_subject_paths(graph, subject_sequence)\n",
    "    num_possible_paths = len(_possible_subject_paths)\n",
    "    extra_node_lists = [[node for node in _possible_subject_paths[i] if node not in subject_sequence] for i in range(num_possible_paths)]\n",
    "    \n",
    "    return extra_node_lists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_prob(graph):\n",
    "    _root_node = root_node(graph)\n",
    "    total_black_squares = graph.nodes[_root_node]['black_remains']\n",
    "    prior_prob = 1/total_black_squares\n",
    "    \n",
    "    return prior_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_location(graph, step, visited_locations, current_node, previous_node):\n",
    "    if previous_node == '':\n",
    "        return\n",
    "    \n",
    "    successors = get_successors(graph, current_node)\n",
    "    previous_successors = get_successors(graph, previous_node)\n",
    "    \n",
    "    node_location_dict = nx.get_node_attributes(graph, 'node_location')\n",
    "    \n",
    "    successor_locations = [node_location_dict[k] for k in node_location_dict if k in successors] # Successor locations for current node\n",
    "    previous_successor_locations = [node_location_dict[k] for k in node_location_dict if k in previous_successors] # Successor locations for previous node\n",
    "    \n",
    "    node_locations = list(node_location_dict.values())\n",
    "    \n",
    "    valid_locations = visited_locations.copy()\n",
    "\n",
    "    valid_locations.update(successor_locations)\n",
    "    valid_locations.update(previous_successor_locations)\n",
    "    \n",
    "    \n",
    "    if step in node_locations:\n",
    "        if step in valid_locations:\n",
    "            pass\n",
    "        else:\n",
    "            return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_node_paths(graph, chosen_path):\n",
    "    _all_node_paths = all_node_paths(graph)\n",
    "    alt_node_paths = _all_node_paths.copy()\n",
    "    alt_node_paths.remove(chosen_path)\n",
    "    \n",
    "    path_value_dict = {','.join(path):generic_path_value(graph, path) for path in alt_node_paths} # Keys are a string of nodes seperated by commas. Use list.split() method to convert into list.\n",
    "    \n",
    "    return path_value_dict\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Path analysis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_path(graph, path): # Takes path string as input.\n",
    "    PRIOR_PROB = prior_prob(graph)\n",
    "    steps_so_far = 0\n",
    "    \n",
    "    current_node_value = 0\n",
    "    current_node = root_node(graph)\n",
    "    previous_node = ''\n",
    "    node_sequence = [root_node(graph)]\n",
    "    path_value = 0\n",
    "    input_path = parse_path_string(path)\n",
    "    LEAF_NODES = leaf_nodes(graph)\n",
    "    subject_graph = deepcopy(graph)\n",
    "    \n",
    "    all_visited_locations = {'(0,0)'} # First visited location is subject's starting position.\n",
    "\n",
    "    for step in input_path[1:]:\n",
    "        if valid_location(subject_graph, step, all_visited_locations, current_node, previous_node) is False:\n",
    "            return ['ERROR_PATH', step, current_node]\n",
    "        else:\n",
    "            if location_in_successors(subject_graph, step, current_node) is not False:\n",
    "                steps_so_far += 1\n",
    "                \n",
    "                previous_node = current_node\n",
    "                current_node = location_in_successors(subject_graph, step, current_node)\n",
    "                node_sequence.append(current_node)\n",
    "                \n",
    "                path_value += value_calculation(subject_graph, current_node, steps_so_far, PRIOR_PROB)\n",
    "                current_node_value = path_value\n",
    "                subject_graph.nodes[current_node]['node_value'] = current_node_value\n",
    "                \n",
    "            else:\n",
    "                steps_so_far += 1\n",
    "            all_visited_locations.add(step)\n",
    "    \n",
    "    empirical_path_value = path_value # Saves path value at the last node the subject visited in experiment\n",
    "    empirical_path = node_sequence # Saves sequence of nodes subject visited in experiment\n",
    "    empirical_last_node = current_node\n",
    "    \n",
    "#     print('empirical path is', empirical_path)\n",
    "#     print('empirical step number is', steps_so_far)\n",
    "#     print('empirical pathvalue is', empirical_path_value)\n",
    "#     print('empirical last node is', empirical_last_node)\n",
    "    \n",
    "#     #####################################################################################\n",
    "    _extra_node_lists = extra_node_lists(subject_graph, empirical_path)\n",
    "    path_comparison_dict = {}\n",
    "    \n",
    "    for node_list in _extra_node_lists:\n",
    "        node_sequence = empirical_path\n",
    "        path_value = empirical_path_value\n",
    "        current_node = empirical_last_node\n",
    "        \n",
    "        while True:\n",
    "            try: \n",
    "                next_node = node_list.pop(0)\n",
    "                steps_so_far += subject_graph.succ[current_node][next_node]['steps_from_parent']\n",
    "                \n",
    "                current_node = next_node\n",
    "                node_sequence.append(current_node)\n",
    "                path_value += value_calculation(subject_graph, current_node, steps_so_far, PRIOR_PROB)\n",
    "                current_node_value = path_value\n",
    "                subject_graph.nodes[current_node]['node_value'] = current_node_value\n",
    "\n",
    "            except IndexError: # Stop while loop when we have reached the last node in the current node list\n",
    "                path_comparison_dict[','.join(node_sequence)] = path_value\n",
    "                break\n",
    "                \n",
    "    final_path_string = min(path_comparison_dict, key = lambda k: path_comparison_dict[k]) # If the subject did not reach a leaf, this is the path we assume the subject would have taken (the optimal choice).\n",
    "    final_path = final_path_string.split(',')\n",
    "    final_path_value = path_comparison_dict[final_path_string]\n",
    "    \n",
    "    alt_path_values = sorted(list(\n",
    "        alt_node_paths(subject_graph, final_path).values()\n",
    "                                ))\n",
    "    \n",
    "    all_values = [str(round(final_path_value, 3))]\n",
    "    all_values.extend([str(round(num, 3)) for num in alt_path_values])\n",
    "\n",
    "    output = [final_path_string, round(final_path_value, 3)]\n",
    "    output.append(';'.join(all_values))\n",
    "    \n",
    "#     return output\n",
    "    \n",
    "#   print(node_sequence)\n",
    "    print(path_comparison_dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N3151,N8688,N1452,N8106,N3650,N4693,N4422,N6940': 21.5, 'N3151,N8688,N1452,N8106,N3650,N4693,N4422,N6940,N8688,N1452,N8106,N3650,N4693,N500,N4478': 36.66666666666667, 'N3151,N8688,N1452,N8106,N3650,N4693,N4422,N6940,N8688,N1452,N8106,N3650,N4693,N500,N4478,N8688,N1452,N54,N4714,N3570,N8310,N5359': 52.74999999999999, 'N3151,N8688,N1452,N8106,N3650,N4693,N4422,N6940,N8688,N1452,N8106,N3650,N4693,N500,N4478,N8688,N1452,N54,N4714,N3570,N8310,N5359,N8688,N1452,N54,N4714,N3570,N3015,N7821': 74.41666666666667, 'N3151,N8688,N1452,N8106,N3650,N4693,N4422,N6940,N8688,N1452,N8106,N3650,N4693,N500,N4478,N8688,N1452,N54,N4714,N3570,N8310,N5359,N8688,N1452,N54,N4714,N3570,N3015,N7821,N8688,N1452,N54,N4714,N3348,N8906,N6836': 98.91666666666664, 'N3151,N8688,N1452,N8106,N3650,N4693,N4422,N6940,N8688,N1452,N8106,N3650,N4693,N500,N4478,N8688,N1452,N54,N4714,N3570,N8310,N5359,N8688,N1452,N54,N4714,N3570,N3015,N7821,N8688,N1452,N54,N4714,N3348,N8906,N6836,N8688,N1452,N54,N4714,N3348,N9384,N3970': 120.74999999999997, 'N3151,N8688,N1452,N8106,N3650,N4693,N4422,N6940,N8688,N1452,N8106,N3650,N4693,N500,N4478,N8688,N1452,N54,N4714,N3570,N8310,N5359,N8688,N1452,N54,N4714,N3570,N3015,N7821,N8688,N1452,N54,N4714,N3348,N8906,N6836,N8688,N1452,N54,N4714,N3348,N9384,N3970,N8688,N1452,N54,N4714,N7197,N2604,N5354': 147.24999999999997, 'N3151,N8688,N1452,N8106,N3650,N4693,N4422,N6940,N8688,N1452,N8106,N3650,N4693,N500,N4478,N8688,N1452,N54,N4714,N3570,N8310,N5359,N8688,N1452,N54,N4714,N3570,N3015,N7821,N8688,N1452,N54,N4714,N3348,N8906,N6836,N8688,N1452,N54,N4714,N3348,N9384,N3970,N8688,N1452,N54,N4714,N7197,N2604,N5354,N8688,N1452,N54,N4714,N7197,N125,N877': 172.41666666666666, 'N3151,N8688,N1452,N8106,N3650,N4693,N4422,N6940,N8688,N1452,N8106,N3650,N4693,N500,N4478,N8688,N1452,N54,N4714,N3570,N8310,N5359,N8688,N1452,N54,N4714,N3570,N3015,N7821,N8688,N1452,N54,N4714,N3348,N8906,N6836,N8688,N1452,N54,N4714,N3348,N9384,N3970,N8688,N1452,N54,N4714,N7197,N2604,N5354,N8688,N1452,N54,N4714,N7197,N125,N877,N8688,N1452,N54,N1420,N628,N3428,N5533': 197.99999999999997, 'N3151,N8688,N1452,N8106,N3650,N4693,N4422,N6940,N8688,N1452,N8106,N3650,N4693,N500,N4478,N8688,N1452,N54,N4714,N3570,N8310,N5359,N8688,N1452,N54,N4714,N3570,N3015,N7821,N8688,N1452,N54,N4714,N3348,N8906,N6836,N8688,N1452,N54,N4714,N3348,N9384,N3970,N8688,N1452,N54,N4714,N7197,N2604,N5354,N8688,N1452,N54,N4714,N7197,N125,N877,N8688,N1452,N54,N1420,N628,N3428,N5533,N8688,N1452,N54,N1420,N628,N9932,N4594': 217.16666666666666}\n"
     ]
    }
   ],
   "source": [
    "analyze_path(graphs['library'], 'p(0,0);p(0,1);p(1,1);p(1,2);p(1,3);p(1,4);p(1,3);p(2,3);p(3,3);p(4,3);p(5,3);p(6,3);p(6,4);')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Analyze experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data_file):\n",
    "    experiment_data_frame = pd.read_csv(data_file, sep='\\t')\n",
    "\n",
    "    previous_subject = ''\n",
    "    previous_world = ''\n",
    "    previous_path = ''\n",
    "    # previous_index = 0\n",
    "    parsed_data = []\n",
    "\n",
    "    # i = 0\n",
    "    for row in experiment_data_frame.itertuples():\n",
    "        if previous_subject != row[1]:\n",
    "            parsed_data.append([previous_subject, previous_world, previous_path])\n",
    "\n",
    "    #     previous_index = index + 2\n",
    "        previous_subject = row[1]\n",
    "        previous_world = row[2]\n",
    "        previous_path = row[3]\n",
    "\n",
    "    parsed_data.append( # Add last row of the data frame manually, since algorithm above misses it\n",
    "                      [experiment_data_frame.iloc[-1]['subject'], \n",
    "                       experiment_data_frame.iloc[-1]['world'], \n",
    "                       experiment_data_frame.iloc[-1]['squarepath']\n",
    "                      ]\n",
    "                     )    \n",
    "\n",
    "    #     if i == 2000:\n",
    "    #         break\n",
    "    #     i += 1\n",
    "\n",
    "    parsed_data.pop(0)\n",
    "\n",
    "    return parsed_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = parse_data('SquareLabelsWithRT_E2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(parsed_data):\n",
    "    num_error_paths = 0\n",
    "    output_data = deepcopy(parsed_data)\n",
    "\n",
    "    for row in output_data: # Analyze path that each subject followed\n",
    "        graph_name = row[1]\n",
    "        input_path = row[2]\n",
    "        path_analysis = analyze_path(graphs[graph_name], input_path)\n",
    "        row.extend(path_analysis)\n",
    "\n",
    "        if path_analysis[0] == 'ERROR_PATH':\n",
    "            num_error_paths += 1\n",
    "\n",
    "    print(f'{len(output_data)} paths analyzed')\n",
    "    print(f'There are {num_error_paths} error paths')\n",
    "    \n",
    "    return output_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512 paths analyzed\n",
      "There are 45 error paths\n"
     ]
    }
   ],
   "source": [
    "output_data = analyze_data(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export path analysis as csv\n",
    "def export_results(output_data):\n",
    "    column_titles = ['subject', 'world', 'square_path', 'chosen_node_path', 'chosen_value', 'all_values'] # The first item in the column 'all_values' is the chosen value\n",
    "\n",
    "    with open('anaylzed_subject_data.csv', 'w') as file:\n",
    "        file_writer = csv.writer(file, delimiter='\\t')\n",
    "        file_writer.writerow(column_titles)\n",
    "\n",
    "        for row in output_data:\n",
    "            file_writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export error data\n",
    "def export_error_data(output_data):\n",
    "    error_data = []\n",
    "    for row in output_data:\n",
    "        if row[3] == 'ERROR_PATH':\n",
    "            error_data.append(row)\n",
    "\n",
    "    column_titles = ['subject', 'world', 'square_path', 'path_type', 'error_step', 'error_node']\n",
    "\n",
    "    with open('error_data.csv', 'w') as file:\n",
    "        file_writer = csv.writer(file, delimiter='\\t')\n",
    "        file_writer.writerow(column_titles)\n",
    "\n",
    "        for row in error_data:\n",
    "            file_writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_error_data(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update graph nodes with successor values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N6609': 0.0,\n",
       " 'N2554': 2.2,\n",
       " 'N2200': 3.5,\n",
       " 'N6588': 3.4,\n",
       " 'N5553': 7.3999996,\n",
       " 'N6173': 6.2,\n",
       " 'N7822': 6.8,\n",
       " 'N3405': 10.599999,\n",
       " 'N5323': 8.2}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.get_node_attributes(graphs['courtyard'], 'node_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N6609\n",
      "N2554\n",
      "N2200\n",
      "N6588\n",
      "N5553\n",
      "N6173\n",
      "N7822\n",
      "N3405\n",
      "N5323\n"
     ]
    }
   ],
   "source": [
    "for node in graphs[graph].nodes():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
